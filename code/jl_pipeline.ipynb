{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 18:15:17.664932: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-29 18:15:17.739646: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-29 18:15:18.122220: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-29 18:15:18.122261: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-29 18:15:18.122265: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import enum\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from spear.labeling import PreLabels\n",
    "import numpy as np\n",
    "from spear.cage import Cage\n",
    "from utils import custom_dataset, train_all_LF, get_various_data\n",
    "from generate_LF import get_variables\n",
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelling_function import *\n",
    "from PIL import Image\n",
    "from resnet18 import ResNet, BasicBlock\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from resnet18 import ResNet, BasicBlock\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = None\n",
    "\n",
    "class ClassLabels(enum.Enum):\n",
    "    LYMPHOCYTE= 0\n",
    "    NONLYMPHOCYTE = 1\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "import re\n",
    "# path = \"/home/akshit/Desktop/MICCAI/data/models/\"\n",
    "path = \"/home/raja/Desktop/MICCAI/data/models/100/\"\n",
    "\n",
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    #x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    svm = pickle.load(open(path+'0_svmV11.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][0]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm_V1, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_svm0_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    #x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'0_svmV11.pkl','rb'))\n",
    "    \n",
    "    if svm.predict_proba([x])[0][0]>0.50: \n",
    "        return ClassLabels.LYMPHOCYTE # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm1_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    #x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    svm = pickle.load(open(path+'1_svmV11.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm1_V1, label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LF_svm1_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    #x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'1_svmV11.pkl','rb'))\n",
    "    \n",
    "    if svm.predict_proba([x])[0][1]>0.6: \n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else: \n",
    "        return ABSTAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelling_function import *\n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL1(c,**kwargs): \n",
    "    red_score = calculate_brown_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    green_score = calculate_green_score(c)\n",
    "    if blue_score > 155:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL2(c,**kwargs): \n",
    "    red_score = calculate_brown_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    if 10 < blue_score < 180 and red_score > 170:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN    \n",
    "    \n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL9(c,**kwargs): \n",
    "    green_score = calculate_green_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    if 10 < blue_score < 180 and green_score > 155:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN      \n",
    "    \n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL3(c,**kwargs): \n",
    "    brown_score = compute_brown_score(c)\n",
    "    total_blue_score = compute_blue_score(c)\n",
    "    if total_blue_score < 12:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN   \n",
    "\n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL4(c,**kwargs): \n",
    "    brown_score = compute_brown_score(c)\n",
    "    total_blue_score = compute_blue_score(c)\n",
    "    if brown_score > 585:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN   \n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL5(c,**kwargs): \n",
    "    red_score = calculate_brown_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    green_score = calculate_green_score(c)\n",
    "    if red_score > 170:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL6(c,**kwargs): \n",
    "    red_score = calculate_brown_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    green_score = calculate_green_score(c)\n",
    "    if red_score < 12:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL7(c,**kwargs): \n",
    "    red_score = calculate_brown_score(c)\n",
    "    blue_score = calculate_blue_score(c)\n",
    "    green_score = calculate_green_score(c)\n",
    "    if green_score > 155:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "@labeling_function(label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LFNL8(c,**kwargs): \n",
    "    black_score = compute_black_score(c)\n",
    "    if black_score > 9:\n",
    "        return ClassLabels.NONLYMPHOCYTE\n",
    "    else:\n",
    "        return ABSTAIN           \n",
    "\n",
    "    \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spear.labeling import LFSet\n",
    "\n",
    "LFS = [\n",
    "    #ResNet18LF_LYMPHOCYTE,\n",
    "    #ResNet18LF_NONLYMPHOCYTE,\n",
    "    LFNL1,\n",
    "    LFNL2,\n",
    "    LFNL3,\n",
    "    LFNL4,\n",
    "    LFNL5,\n",
    "    LFNL6,\n",
    "    LFNL7,\n",
    "    LFNL8,\n",
    "    LFNL9,\n",
    "    \n",
    "    LF_svm0_V1,\n",
    "    LF_svm1_V1,  \n",
    "  \n",
    "]\n",
    "\n",
    "QT2 = 0.99\n",
    "QC2 = 0.99\n",
    "\n",
    "qt1 = np.array([0.9999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999])\n",
    "qc1 = np.array([0.99999,0.99999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999])\n",
    "\n",
    "rules = LFSet(\"BM_LF\")\n",
    "rules.add_lf_list(LFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import custom_dataset, train_all_LF, get_various_data\n",
    "from generate_LF import get_variables\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "classes,label_frac,data_path,save_path = get_variables()\n",
    "dataset,X,Y = custom_dataset(classes=classes,path=data_path ,fraction=label_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 2700)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "X, X_feats, Y = X, X, Y\n",
    "\n",
    "#X = X.reshape((210,30, 30, 3))\n",
    "\n",
    "validation_size = 10\n",
    "test_size = 10\n",
    "L_size = 10\n",
    "U_size = 180\n",
    "n_lfs = len(rules.get_lfs())\n",
    "\n",
    "X_V, Y_V, X_feats_V,_, X_T, Y_T, X_feats_T,_, X_L, Y_L, X_feats_L,_, X_U, X_feats_U,_ = get_various_data(X, Y, X_feats, n_lfs, validation_size, test_size, L_size, U_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_json = './jl_pkl/sms_json.json'\n",
    "V_path_pkl = './jl_pkl/sms_pickle_V.pkl' #validation data - have true labels\n",
    "T_path_pkl = './jl_pkl/sms_pickle_T.pkl' #test data - have true labels\n",
    "L_path_pkl = './jl_pkl/sms_pickle_L.pkl' #Labeled data - have true labels\n",
    "U_path_pkl = './jl_pkl/sms_pickle_U.pkl' #unlabelled data - don't have true labels\n",
    "\n",
    "U_path_pkl1 = './jl_pkl/sms_pickle_U1.pkl' #unlabelled data - don't have true labels\n",
    "\n",
    "log_path_jl_1 = './jl_pkl/sms_log_1.txt' #jl is an algorithm, can be found below\n",
    "params_path = './jl_pkl/sms_params.pkl' #file path to store parameters of JL, used below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained & Saved 6 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained & Saved 6 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 469.00it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 462.24it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 449.31it/s]\n",
      "100%|██████████| 180/180 [00:00<00:00, 583.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from spear.labeling import PreLabels\n",
    "classes,label_frac,data_path,save_path = get_variables()\n",
    "train_all_LF(X,Y,len(classes),save_path,label_frac)\n",
    "\n",
    "sms_noisy_labels = PreLabels(name=\"lysto\",\n",
    "                               data=X_V,\n",
    "                               gold_labels=Y_V,\n",
    "                               data_feats=X_feats_V,\n",
    "                               rules=rules,\n",
    "                               labels_enum=ClassLabels,\n",
    "                               num_classes=2)\n",
    "sms_noisy_labels.generate_pickle(V_path_pkl)\n",
    "sms_noisy_labels.generate_json(path_json) #generating json files once is enough\n",
    "\n",
    "sms_noisy_labels = PreLabels(name=\"lysto\",\n",
    "                               data=X_T,\n",
    "                               gold_labels=Y_T,\n",
    "                               data_feats=X_feats_T,\n",
    "                               rules=rules,\n",
    "                               labels_enum=ClassLabels,\n",
    "                               num_classes=2)\n",
    "sms_noisy_labels.generate_pickle(T_path_pkl)\n",
    "\n",
    "sms_noisy_labels = PreLabels(name=\"lysto\",\n",
    "                               data=X_L,\n",
    "                               gold_labels=Y_L,\n",
    "                               data_feats=X_feats_L,\n",
    "                               rules=rules,\n",
    "                               labels_enum=ClassLabels,\n",
    "                               num_classes=2)\n",
    "sms_noisy_labels.generate_pickle(L_path_pkl)\n",
    "\n",
    "sms_noisy_labels = PreLabels(name=\"lysto\",\n",
    "                               data=X_U,\n",
    "                               rules=rules,\n",
    "                               data_feats=X_feats_U,\n",
    "                               labels_enum=ClassLabels,\n",
    "                               num_classes=2) #note that we don't pass gold_labels here, for the unlabelled data\n",
    "sms_noisy_labels.generate_pickle(U_path_pkl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: (180, 2700)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the labeled data from the pickle file\n",
    "with open(U_path_pkl, 'rb') as f:\n",
    "    labeled_data = pickle.load(f)\n",
    "\n",
    "# Get the feature matrix from the labeled data\n",
    "U_L = labeled_data\n",
    "\n",
    "# Determine the number of features\n",
    "n_features = U_L.shape\n",
    "\n",
    "print(\"Number of features:\", n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in data list:  10\n",
      "Shape of feature matrix:  (180, 2700)\n",
      "Shape of labels matrix:  (180, 11)\n",
      "Shape of continuous scores matrix :  (180, 11)\n",
      "Total number of classes:  2\n",
      "Classes dictionary in json file(modified to have integer keys):  {0: 'LYMPHOCYTE', 1: 'NONLYMPHOCYTE'}\n"
     ]
    }
   ],
   "source": [
    "from spear.utils import get_data, get_classes\n",
    "\n",
    "data_U = get_data(path = U_path_pkl, check_shapes=True)\n",
    "#check_shapes being True(above), asserts for relative shapes of arrays in pickle file\n",
    "print(\"Number of elements in data list: \", len(data_U))\n",
    "print(\"Shape of feature matrix: \", data_U[0].shape)\n",
    "print(\"Shape of labels matrix: \", data_U[1].shape)\n",
    "print(\"Shape of continuous scores matrix : \", data_U[6].shape)\n",
    "print(\"Total number of classes: \", data_U[9])\n",
    "\n",
    "classes = get_classes(path = path_json)\n",
    "print(\"Classes dictionary in json file(modified to have integer keys): \", classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in data list:  10\n",
      "Shape of feature matrix:  (10, 2700)\n",
      "Shape of labels matrix:  (10, 11)\n",
      "Shape of continuous scores matrix :  (10, 11)\n",
      "Total number of classes:  2\n",
      "Classes dictionary in json file(modified to have integer keys):  {0: 'LYMPHOCYTE', 1: 'NONLYMPHOCYTE'}\n"
     ]
    }
   ],
   "source": [
    "from spear.utils import get_data, get_classes\n",
    "\n",
    "data_U = get_data(path = L_path_pkl, check_shapes=True)\n",
    "#check_shapes being True(above), asserts for relative shapes of arrays in pickle file\n",
    "print(\"Number of elements in data list: \", len(data_U))\n",
    "print(\"Shape of feature matrix: \", data_U[0].shape)\n",
    "print(\"Shape of labels matrix: \", data_U[1].shape)\n",
    "print(\"Shape of continuous scores matrix : \", data_U[6].shape)\n",
    "print(\"Total number of classes: \", data_U[9])\n",
    "\n",
    "classes = get_classes(path = path_json)\n",
    "print(\"Classes dictionary in json file(modified to have integer keys): \", classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raja/Desktop/cage/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/raja/Desktop/cage/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from spear.jl import JL\n",
    "\n",
    "n_features = 2700\n",
    "n_hidden = 512\n",
    "feature_model = 'resnet'\n",
    "'''\n",
    "'nn' is neural network. other alternative is 'lr'(logistic regression) which doesn't need n_hidden to be passed\n",
    "during initialisation.\n",
    "''' \n",
    "\n",
    "jl = JL(path_json = path_json, n_lfs = n_lfs, n_features = n_features, feature_model = feature_model, \\\n",
    "        n_hidden = n_hidden)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [00:08<00:36,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early stopping at epoch: 19\tbest_epoch: 8\n",
      "score used: f1_score\n",
      "best_gm_val_score:0.8571428571428571\tbest_fm_val_score:0.5\n",
      "best_gm_test_score:1.0\tbest_fm_test_score:0.5714285714285715\n",
      "best_gm_test_precision:1.0\tbest_fm_test_precision:0.4\n",
      "best_gm_test_recall:1.0\tbest_fm_test_recall:1.0\n",
      "probs_fm shape:  (180, 2)\n",
      "probs_gm shape:  (180, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_func_mask = [1,1,1,1,1,1,1] \n",
    "#loss_func_mask = [0,0,0,0,0,0,1]\n",
    "'''\n",
    "One can keep 0s in places where he don't want the specific loss function to be part\n",
    "the final loss function used in training. Refer documentation(spear.JL.core.JL) to understand\n",
    "the which index of loss_func_mask refers to what loss function.\n",
    "\n",
    "Note: the loss_func_mask above may not be the optimal mask for sms dataset. We have to try\n",
    "      some other masks too, to find the best one that gives good accuracies.\n",
    "'''\n",
    "batch_size = 500\n",
    "lr_fm = 0.0005\n",
    "lr_gm = 0.01\n",
    "use_accuracy_score = False\n",
    "\n",
    "jl = JL(path_json = path_json, n_lfs = n_lfs, n_features = n_features, feature_model = feature_model, n_hidden = n_hidden)\n",
    "\n",
    "probs_fm, probs_gm = jl.fit_and_predict_proba(path_L = L_path_pkl, path_U = U_path_pkl, path_V = V_path_pkl, path_T = T_path_pkl, loss_func_mask = loss_func_mask, batch_size = batch_size, lr_fm = lr_fm, lr_gm = lr_gm, use_accuracy_score = use_accuracy_score, path_log = log_path_jl_1, return_gm = True, n_epochs = 100, start_len = 7,stop_len = 10, is_qt = True, is_qc = True, qt = 0.99, qc = 0.99, metric_avg = 'binary')\n",
    "\n",
    "labels = np.argmax(probs_fm, 1)\n",
    "labels1 = np.argmax(probs_gm, 1)\n",
    "print(\"probs_fm shape: \", probs_fm.shape)\n",
    "print(\"probs_gm shape: \", probs_gm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107, 2700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14485/777400022.py:16: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(image_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "image_folder = '/home/raja/Desktop/MICCAI/test_folder'\n",
    "\n",
    "image_folder = '/home/raja/Desktop/segment-anything/output/NONLYM'\n",
    "image_folder = '/home/raja/Desktop/segment-anything/output/TRAIN/LYMPHOCYTES'\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "image_data = []\n",
    "image_names = []\n",
    "for file in image_files:\n",
    "    image_path = os.path.join(image_folder, file)\n",
    "    image = imageio.imread(image_path)\n",
    "    resized_image = resize(image, (30, 30, 3))\n",
    "    image_data.append(resized_image)\n",
    "    image_names.append(file)\n",
    "\n",
    "xuu = (np.array(image_data) * 255).astype(np.uint8)\n",
    "\n",
    "# Reshape xuu to (num_images, 2700)\n",
    "xuu_reshaped = xuu.reshape(xuu.shape[0], -1)\n",
    "print(xuu_reshaped.shape)  # (num_images, 2700)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:00<00:00, 614.24it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_feats_UUU = xuu_reshaped\n",
    "sms_noisy_labels = PreLabels(name=\"lysto\",\n",
    "                               data=xuu_reshaped,\n",
    "                               rules=rules,\n",
    "                               data_feats=X_feats_UUU,\n",
    "                               labels_enum=ClassLabels,\n",
    "                               num_classes=2) #note that we don't pass gold_labels here, for the unlabelled data\n",
    "sms_noisy_labels.generate_pickle(U_path_pkl1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raja/Desktop/cage/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/raja/Desktop/cage/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "  2%|▏         | 19/1000 [00:03<03:23,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early stopping at epoch: 19\tbest_epoch: 8\n",
      "score used: f1_score\n",
      "best_gm_val_score:0.8571428571428571\tbest_fm_val_score:0.4615384615384615\n",
      "best_gm_test_score:1.0\tbest_fm_test_score:0.5714285714285715\n",
      "best_gm_test_precision:1.0\tbest_fm_test_precision:0.4\n",
      "best_gm_test_recall:1.0\tbest_fm_test_recall:1.0\n",
      "probs_fm shape:  (107, 2)\n",
      "probs_gm shape:  (107, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "lr_fm = 0.0005\n",
    "lr_gm = 0.01\n",
    "use_accuracy_score = False\n",
    "\n",
    "jl = JL(path_json = path_json, n_lfs = n_lfs, n_features = n_features, feature_model = feature_model, n_hidden = n_hidden)\n",
    "\n",
    "probs_fm, probs_gm = jl.fit_and_predict_proba(path_L = L_path_pkl, path_U = U_path_pkl1, path_V = V_path_pkl, path_T = T_path_pkl, loss_func_mask = loss_func_mask, batch_size = batch_size, lr_fm = lr_fm, lr_gm = lr_gm, use_accuracy_score = use_accuracy_score, path_log = log_path_jl_1, return_gm = True, n_epochs = 1000, start_len = 7,stop_len = 10, is_qt = True, is_qc = True, qt = 0.99, qc = 0.99, metric_avg = 'binary')\n",
    "\n",
    "labels_fm = np.argmax(probs_fm, 1)\n",
    "labels_gm = np.argmax(probs_gm, 1)\n",
    "print(\"probs_fm shape: \", probs_fm.shape)\n",
    "print(\"probs_gm shape: \", probs_gm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raja/Desktop/cage/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/raja/Desktop/cage/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      " 19%|█▉        | 19/100 [00:07<00:30,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early stopping at epoch: 19\tbest_epoch: 8\n",
      "score used: f1_score\n",
      "best_gm_val_score:1.0\tbest_fm_val_score:0.888888888888889\n",
      "best_gm_test_score:0.9333333333333333\tbest_fm_test_score:0.8235294117647058\n",
      "best_gm_test_precision:0.875\tbest_fm_test_precision:0.7\n",
      "best_gm_test_recall:1.0\tbest_fm_test_recall:1.0\n",
      "labels_fm shape:  (180,)\n",
      "labels_gm shape:  (180,)\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_func_mask = [1,1,1,1,1,1,1] \n",
    "feature_model = 'resnet' #resetting feature_model as 'nn'(neural network) for further trainings\n",
    "\n",
    "jl = JL(path_json = path_json, n_lfs = n_lfs, n_features = n_features, feature_model = feature_model, \\\n",
    "        n_hidden = n_hidden)\n",
    "\n",
    "labels_fm, labels_gm = jl.fit_and_predict(path_L = L_path_pkl, path_U = U_path_pkl, path_V = V_path_pkl, \\\n",
    "        path_T = T_path_pkl, loss_func_mask = loss_func_mask, batch_size = batch_size, lr_fm = lr_fm, lr_gm = \\\n",
    "    lr_gm, use_accuracy_score = use_accuracy_score, path_log = log_path_jl_1, return_gm = True, n_epochs = \\\n",
    "    100, start_len = 7,stop_len = 10, is_qt = True, is_qc = True, qt = 0.9, qc = 0.85, metric_avg = 'binary', \\\n",
    "    need_strings = False)\n",
    "\n",
    "print(\"labels_fm shape: \", labels_fm.shape)\n",
    "print(\"labels_gm shape: \", labels_gm.shape)\n",
    "print(type(labels_fm[0]))\n",
    "print(type(labels_gm[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmax(probs_fm, 1)\n",
    "labels1 = np.argmax(probs_gm, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  6%|▌         | 6/100 [00:00<00:07, 12.92it/s]/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  8%|▊         | 8/100 [00:00<00:07, 12.98it/s]/home/raja/Desktop/cage/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 19%|█▉        | 19/100 [00:01<00:06, 12.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early stopping at epoch: 19\tbest_epoch: 9\n",
      "score used: f1_score\n",
      "best_gm_val_score:1.0\tbest_fm_val_score:0.888888888888889\n",
      "best_gm_test_score:0.9333333333333333\tbest_fm_test_score:0.8235294117647058\n",
      "best_gm_test_precision:0.875\tbest_fm_test_precision:0.7\n",
      "best_gm_test_recall:1.0\tbest_fm_test_recall:1.0\n",
      "labels_fm shape:  (180,)\n",
      "labels_gm shape:  (180,)\n",
      "<class 'numpy.str_'>\n",
      "<class 'numpy.str_'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "jl = JL(path_json = path_json, n_lfs = n_lfs, n_features = n_features, feature_model = feature_model, \\\n",
    "        n_hidden = n_hidden)\n",
    "\n",
    "labels_fm, labels_gm = jl.fit_and_predict(path_L = L_path_pkl, path_U = U_path_pkl, path_V = V_path_pkl, \\\n",
    "        path_T = T_path_pkl, loss_func_mask = loss_func_mask, batch_size = batch_size, lr_fm = lr_fm, lr_gm = \\\n",
    "    lr_gm, use_accuracy_score = use_accuracy_score, path_log = log_path_jl_1, return_gm = True, n_epochs = \\\n",
    "    100, start_len = 7,stop_len = 10, is_qt = True, is_qc = True, qt = 0.9, qc = 0.85, metric_avg = 'binary', \\\n",
    "    need_strings = True)\n",
    "\n",
    "print(\"labels_fm shape: \", labels_fm.shape)\n",
    "print(\"labels_gm shape: \", labels_gm.shape)\n",
    "print(type(labels_fm[0]))\n",
    "print(type(labels_gm[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f5b4396ae54b339dce7091723dfd2c38ad833227f8e97d2a6323021886247d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
